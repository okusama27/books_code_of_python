# 4章 データ前処理—よりよいトレーニングセットの構築

## 順序特徴量
- Tシャツのサイズの用に順序があるようなものはデータが欠損している場合は平均値を入れるなどできる。
- 順序が存在しないものに順序付けをしてはいけない

## one-hotエンコーディング
- 順序付けできないものは、要素数分次元を作る
緑は[1, 0, 0]
青は[0, 1, 0]
赤は[0, 0, 1]
のようにする

## fit

## 正規化（ normalization） 
- 正規化は特徴量を[0,1]の範囲にスケーリングし直すことを意味する。
- 最大と最小値を使って、0〜1の間にスケーリングしようとすると、外れ値があった場合にそれに影響を受ける

## 標準化（ standardization）
- 標準化を使用する場合、平均値0、標準偏差1となるように変換する。
- 特徴量の列は正規分布に従うため、重みを学習しやすくなる。
- さらに、標準化では、外れ値に関する有益な情報が維持される

一般的には標準化が使われて、正規化は特別な理由がないと使われない　

## 正則化
参照：　http://tjo.hatenablog.com/entry/2015/03/03/190000

http://qiita.com/kenmatsu4/items/cecb466437da33df2870

両方、過学習を押さえるのには有効
L1は余計なデータが沢山ある場合はいいが、L2正則化を利用するのが一般的。

### L1正則化
L1正則化によって返されるのは疎な特徴ベクトルであり、ほとんどの特徴量の重みは0となる。要素のほとんどが0といった疎性が実際に役立つことがあるのは、無関係な特徴量の個数が多い高次元のデータセットがあり、特に無関係な次元の数がサンプルよりも多い場合である。

### L2正則化
L2正則化がモデルの複雑さを低減する方法の1つであることを示した。
モデルの複雑さは大きな重みにペナルティを科すことによって低減される。

