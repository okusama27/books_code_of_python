{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.1\r\n"
     ]
    }
   ],
   "source": [
    "# 前準備\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitignore', '.ipynb_checkpoints', 'chapter02.ipynb', 'chapter03.ipynb', 'chapter04.ipynb', 'chapter05.ipynb', 'chapter06.ipynb', 'chapter07.ipynb', 'chapter08.ipynb', 'chapter09.ipynb', 'dataset', 'env', 'README.md']\n",
      "['data_documentation.txt', 'document_word_data.json', 'document_word_data_pnoun.json', 'kc_house_data.csv', 'mix20_rand700_tokens.zip', 'README', 'tokens', 'user_topic_follow_dummy.csv', 'Wholesale_customers_data.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print( os.listdir(os.path.normpath(\"./\")) )\n",
    "print( os.listdir(os.path.normpath(\"./dataset/\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your default locale is None\n",
      "Your locale is set as ja_JP.UTF-8\n"
     ]
    }
   ],
   "source": [
    "# dataの読み込みとモジュールのインポート\n",
    "def set_locale():\n",
    "    default = os.environ.get('LC_ALL')\n",
    "    print( \"Your default locale is\", default )\n",
    "    if default is None:\n",
    "        os.environ.setdefault('LC_ALL', 'ja_JP.UTF-8')\n",
    "        print( \"Your locale is set as ja_JP.UTF-8\" )\n",
    "\n",
    "set_locale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/tokens/neg/cv000_tok-9611.txt', 'dataset/tokens/neg/cv001_tok-19324.txt']\n",
      "['dataset/tokens/pos/cv000_tok-11609.txt', 'dataset/tokens/pos/cv001_tok-10180.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "neg_files = glob.glob( os.path.normpath(\"./dataset/tokens/neg/*\") )\n",
    "pos_files = glob.glob( os.path.normpath(\"./dataset/tokens/pos/*\") )\n",
    "print(neg_files[0:2])\n",
    "print(pos_files[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def text_reader(file_path):\n",
    "    python_version = sys.version_info.major\n",
    "    \n",
    "    if python_version >= 3:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                print(line)\n",
    "    else:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ( out of 4 = poor ) 1995 , g , 90 minutes [1 hour , 30 minutes] [comedy] starring : michael roescher ( hank royce ) , kristy young ( jinnie sue macallister ) , justin garms ( voice of gordy ) , james donadio ( gilbert sipes ) , written by leslie stevens , jay sommers , dick chevillat , produced by sybil robson , directed by mark lewis . \" gordy \" is not a movie , it is a 90-minute-long \" sesame street \" skit , and a very bad one at that . this movie is so stupid and dumb that it's depressing to think that some hollywood executives actually gave this the green light , and even more surprising is the fact that this is a disney movie . i'm sure children are the target audience of this movie , but only kids under the age of five may be able to tolerate it . it is the story of a farm a piglet named gordy ( voiced by garms ) , whose family has been taken away to \" up north , \" which we know means death . of course we can hear the animals talk to each other , and they actually went to the trouble of attempting to sync the voices with their mouths but it comes out terrible . actually , it's almost funny in a way . the only remotely interesting and likable character soon appears , a little girl named jinnie sue macallister ( young ) who sees gordy on the back of a truck and essentially steals him . jinnie is a country singer and the film goes off on a huge tangent to show her little concert and the people dancing to it . what is the point of this ? maybe she is one of the producer's relatives and they wanted to show her on camera to promote her or something . we then cut to a huge social gathering and drop in on another young kid named hank royce ( roescher ) who is sad because his divorced mother is dating . he leaves the party and meets jinnie sue , but he accidentally falls in a pool ( probably because he was sitting on the diving board with a $200 suit on - nah , didn't see that one coming ! ) , starts to drown , and is miraculously saved as gordy pushes an inflatable float over to him and saves him . if this had not been insanely stupid already the story quickly changes when jinnie gives gordy to hank who then ends up becoming the ceo of a food processing corporation when hank's grandfather , the original ceo , dies and leaves his fortune to hank . . . and gordy ! of course there must be a villain , but even this villain ( donadio as sipes ) isn't that evil . he never raises his voice or becomes angry , and of course he has the typical idiot goons kidnap gordy but this is just so beyond stupid and cartoony we are constantly two steps ahead of the story . it's hard to tell whether the overall corniness and cheesiness to the movie is intentional because it is a family film , or if the filmmaker's are just this untalented and stupid . at times \" gordy \" is tolerable to watch , thus earning it one star and not the dreaded \" z- . \" but it's just so unbelievably boring , cliche , dumb , unfunny , corny , and just plain bad it may scare children , it certainly disturbed me . ( 4/21/96 ) ( 1/29/97 ) ( 6/13/97 ) [see also : \" babe \" ]please visit chad'z movie page @ <a href= \" http : //members . aol . com/chadpolenz/index . html \" >http : //members . aol . com/chadpolenz/index . html</a> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_reader(neg_files[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使うモジュールの情報をまとめておきます。\n",
    "詳細な中身などに関してはご自身で調べてみてください。\n",
    "- matplotlib : グラフなどを描写する\n",
    "http://matplotlib.org/\n",
    "- pandas : dataframeでデータを扱い、集計や統計量算出などがすぐ実行できる\n",
    "http://pandas.pydata.org/\n",
    "- collections : pythonで扱えるデータの型を提供する\n",
    "http://docs.python.jp/3/library/collections.html\n",
    "- numpy : 行列などの数学的オブジェクトを扱う\n",
    "http://www.numpy.org/\n",
    "- sklearn.feature_extraction.DictVectorizer : 辞書データをベクトルの形に変換する\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html\n",
    "- sklearnのモデル : SVM, NB, RF\n",
    "http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "- sklearn.grid_search : パラメタの最適な組み合わせ見つける\n",
    "http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib # not used in this notebook\n",
    "# import pandas as pd # not used in this notebook\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn import svm, naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特徴ベクトルの作成\n",
    "def word_counter(string):\n",
    "    words = string.strip().split()\n",
    "    count_dict = collections.Counter(words)\n",
    "    return dict(count_dict)\n",
    "\n",
    "def get_unigram(file_path):\n",
    "    result = []\n",
    "    python_version = sys.version_info.major\n",
    "    \n",
    "    if python_version >= 3:\n",
    "        for file in file_path:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    count_dict = word_counter(line)\n",
    "                    result.append(count_dict)\n",
    "    else:\n",
    "        for file in file_path:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    count_dict = word_counter(line)\n",
    "                    result.append(count_dict)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 2,\n",
       " 'YK.': 1,\n",
       " 'am': 1,\n",
       " 'analysis': 1,\n",
       " 'data': 1,\n",
       " 'love': 1,\n",
       " 'python.': 1,\n",
       " 'using': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter(\"I am YK. I love data analysis using python.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 299 ms, sys: 88.6 ms, total: 388 ms\n",
      "Wall time: 508 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "DATA_NUM = 700\n",
    "\n",
    "unigrams_data = get_unigram(neg_files[:DATA_NUM]) + get_unigram(pos_files[:DATA_NUM])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tristar': 1, '/': 3, '1': 1, ':': 9, '30': 1, '1997': 2, 'r': 1, '(': 6, 'language': 1, ',': 25, 'violence': 1, 'dennis': 3, 'rodman': 7, ')': 6, 'cast': 1, 'jean-claude': 2, 'van': 4, 'damme': 4, ';': 6, 'mickey': 2, 'rourke': 2, 'natacha': 2, 'lindinger': 2, 'paul': 2, 'freeman': 1, 'director': 1, 'tsui': 2, 'hark': 1, 'screenplay': 2, 'dan': 1, 'jakoby': 1, 'mones': 1, 'ripe': 1, 'with': 5, 'explosions': 1, 'mass': 1, 'death': 1, 'and': 17, 'really': 1, 'weird': 1, 'hairdos': 1, \"hark's\": 1, '\"': 22, 'double': 5, 'team': 5, 'must': 1, 'be': 2, 'the': 20, 'result': 2, 'of': 3, 'a': 13, 'tipsy': 1, 'hollywood': 1, 'power': 1, 'lunch': 1, 'that': 10, 'decided': 1, 'needs': 2, 'another': 2, 'notch': 1, 'on': 5, 'his': 4, 'bad': 2, 'movie-bedpost': 1, 'nba': 1, 'superstar': 1, 'should': 2, 'have': 2, 'an': 5, 'acting': 1, 'career': 1, '.': 31, 'actually': 1, 'in': 8, \"neither's\": 1, 'performance': 1, 'is': 9, 'all': 4, \"i've\": 1, 'always': 1, 'been': 1, 'one': 2, 'critic': 1, 'to': 20, 'defend': 1, '--': 3, 'he': 4, 'possesses': 1, 'high': 1, 'charisma': 1, 'level': 1, 'some': 2, 'genre': 1, 'stars': 1, 'namely': 1, 'steven': 1, 'seagal': 1, 'never': 3, 'aim': 1, 'for': 4, \"it's\": 2, 'just': 3, \"he's\": 3, 'made': 1, 'movie': 3, 'so': 3, 'exuberantly': 1, 'witty': 1, 'since': 1, \"1994's\": 1, 'timecop': 1, 'well': 1, 'pretty': 2, 'much': 4, 'extremely': 1, 'colorful': 1, 'therefore': 1, 'fits': 1, 'role': 2, 't': 1, 'even': 1, 'if': 1, 'ex-cia': 1, 'weapons': 1, 'expert': 1, 'story': 1, 'major': 1, 'work': 2, 'plays': 1, 'counter-terrorist': 1, 'operative': 1, 'jack': 1, 'quinn': 5, 'who': 1, 'teams': 1, 'up': 4, 'arms': 1, 'dealer': 1, 'yaz': 3, 'rub': 1, 'out': 3, 'deadly': 1, 'gangster': 1, 'stavros': 4, 'beefy': 1, 'weird-looking': 1, 'antwerp': 1, 'amusement': 1, 'park': 1, 'job': 1, 'botched': 1, 'when': 2, \"stavros'\": 1, 'son': 1, 'gets': 1, 'killed': 1, 'gunfire': 1, 'taken': 1, 'off': 1, 'island': 1, 'known': 1, 'as': 1, 'colony': 1, 'think': 1, 'tank': 1, 'soldiers': 1, 'too': 3, 'valuable': 1, 'kill': 2, 'but': 4, 'dangerous': 1, 'set': 1, 'free': 1, 'escapes': 1, 'tries': 2, 'make': 1, 'it': 2, 'back': 1, 'home': 1, 'pregnant': 1, 'wife': 1, 'revenge': 1, 'kidnaps': 1, 'her': 1, \"what's\": 3, 'kickboxing': 1, 'mercenary': 1, 'do': 4, '?': 3, 'looks': 1, 'two': 1, 'travel': 1, 'rome': 1, 'they': 1, 'can': 1, 'rescue': 1, 'woman': 1, 'save': 1, 'world': 1, 'whatever': 1, 'else': 1, 'requires': 1, 'them': 2, 'crazy': 1, 'often': 1, 'eye-popping': 1, 'camera': 1, 'by': 1, 'peter': 1, 'pau': 1, \"rodman's\": 1, 'lite': 1, 'brite': 1, 'locks': 1, 'mildly': 1, 'enjoyable': 1, 'guilty': 1, 'pleasure': 1, 'happen': 1, 'each': 1, 'frame': 1, 'leaves': 1, 'you': 1, 'exhausted': 1, 'rather': 1, 'than': 1, 'exhilarated': 1, 'numerous': 1, 'action': 1, 'scenes': 1, 'are': 1, 'loud': 1, 'headache-inducing': 1, 'frenetic': 1, 'pacing': 1, 'slows': 1, 'down': 2, 'enough': 1, 'us': 2, 'care': 1, 'about': 1, 'going': 3, 'wacky': 1, \"there's\": 1, 'whole': 1, 'segment': 1, 'devoted': 1, 'net-surfing': 1, 'monks': 1, 'i': 2, 'yet': 1, 'figure': 1, 'climax': 1, 'finds': 1, 'head-to-head': 1, 'tiger': 1, 'roman': 1, 'coliseum': 1, 'while': 2, 'circles': 1, 'motorcycle': 1, 'trying': 1, 'avoid': 1, 'running': 1, 'over': 1, 'land': 1, 'mines': 1, 'hold': 1, \"quinn's\": 1, 'baby': 1, 'boy': 1, \"who's\": 1, 'bomb': 1, 'equipped': 1, 'basket': 1, 'this': 2, 'watches': 1, 'shirtless': 1, 'from': 1, 'bleachers': 1, 'did': 2, 'mention': 1, 'strange': 1, 'comes': 1, 'rarely': 1, 'entertaining': 1, 'formula': 1, 'killathon': 1, 'albeit': 1, 'feels': 1, 'no': 1, 'need': 2, 'indulge': 1, 'gratuitous': 1, 'profanity': 1, 'juices': 1, 'things': 1, 'blatantly': 1, 'vibrant': 1, 'screen': 1, 'persona': 1, 'though': 1, 'leading': 1, 'stunt': 1, 'where': 1, 'kicks': 1, 'opponent': 1, 'between': 1, 'legs': 1, 'we': 2, \"didn't\": 1, 'tell': 1, 'could': 1, 'jamie': 1, 'peck': 1, 'e-mail': 1, '<a': 2, 'href=': 2, 'mailto': 1, 'jpeck1@gl': 1, 'umbc': 4, 'edu': 1, '>jpeck1@gl': 1, 'edu</a>': 1, 'visit': 1, 'reel': 1, 'deal': 1, 'online': 1, 'http': 1, '//www': 2, 'gl': 2, 'edu/~jpeck1/': 1, '>http': 1, 'edu/~jpeck1/</a>': 1}\n",
      "data size : 0.011264 [MB]\n"
     ]
    }
   ],
   "source": [
    "print( unigrams_data[0] )\n",
    "print( \"data size :\", sys.getsizeof(unigrams_data) / 1000000, \"[MB]\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 569 ms, sys: 22.6 ms, total: 592 ms\n",
      "Wall time: 599 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = DictVectorizer()\n",
    "feature_vectors_csr = vec.fit_transform( unigrams_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1400x44219 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 496525 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension : (1400, 44219)\n",
      "[  0.   0.  22. ...,   0.   0.   0.]\n",
      "data size : 495.252912 [MB]\n"
     ]
    }
   ],
   "source": [
    "feature_vectors = vec.fit_transform( unigrams_data ).toarray()\n",
    "print( \"data dimension :\", feature_vectors.shape )\n",
    "print( feature_vectors[0] )\n",
    "print( \"data size :\", sys.getsizeof(feature_vectors) / 1000000, \"[MB]\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 1\n"
     ]
    }
   ],
   "source": [
    "# ラベルデータの作成\n",
    "labels = np.r_[np.tile(0, DATA_NUM), np.tile(1, DATA_NUM)]\n",
    "print( labels[0], labels[DATA_NUM-1], labels[DATA_NUM], labels[2*DATA_NUM-1]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習用データとテスト用データの作成方法\n",
    "np.random.seed(7789)\n",
    "shuffle_order = np.random.choice( 2*DATA_NUM, 2*DATA_NUM, replace=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 1400\n",
      "first 10 elements : [1235 1232  910  162  343 1160  221  545 1112 1322]\n"
     ]
    }
   ],
   "source": [
    "print( \"length :\", len(shuffle_order) )\n",
    "print( \"first 10 elements :\", shuffle_order[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one third of the length : 466\n",
      "# of '1' in 1st set : 227\n",
      "# of '1' in 2nd set : 233\n",
      "# of '1' in 3rd set : 240\n"
     ]
    }
   ],
   "source": [
    "one_third_size = int( 2*DATA_NUM / 3. )\n",
    "print( \"one third of the length :\", one_third_size )\n",
    "\n",
    "print( \"# of '1' in 1st set :\", np.sum( labels[ shuffle_order[:one_third_size] ]  ) )\n",
    "print( \"# of '1' in 2nd set :\", np.sum( labels[ shuffle_order[one_third_size:2*one_third_size] ]  ) )\n",
    "print( \"# of '1' in 3rd set :\", np.sum( labels[ shuffle_order[2*one_third_size:] ]  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルを学習して精度を検証\n",
    "def N_splitter(seq, N):\n",
    "    avg = len(seq) / float(N)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    \n",
    "    while last < len(seq):\n",
    "        out.append( seq[int(last):int(last + avg)] )\n",
    "        last += avg\n",
    "        \n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([range(0, 4), range(4, 9), range(9, 14)], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_splitter(range(14), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習や予測のための関数を定義します。\n",
    "- train_model : 説明変数とラベルと手法を与えることでモデルを学習する\n",
    "- predict : モデルと説明変数を与えることでラベルを予測する\n",
    "- evaluate_model : 予測したラベルと実際の答えの合致数を調べる\n",
    "- cross_validate : cross_validationを実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(features, labels, method='SVM', parameters=None):\n",
    "    ### set the model\n",
    "    if method == 'SVM':\n",
    "        model = svm.SVC()\n",
    "    elif method == 'NB':\n",
    "        model = naive_bayes.GaussianNB()\n",
    "    elif method == 'RF':\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        print(\"Set method as SVM (for Support vector machine), NB (for Naive Bayes) or RF (Random Forest)\")\n",
    "    ### set parameters if exists\n",
    "    if parameters:\n",
    "        model.set_params(**parameters)\n",
    "    ### train the model\n",
    "    model.fit( features, labels )\n",
    "    ### return the trained model\n",
    "    return model\n",
    "\n",
    "def predict(model, features):\n",
    "    predictions = model.predict( features )\n",
    "    return predictions\n",
    "\n",
    "def evaluate_model(predictions, labels):\n",
    "    data_num = len(labels)\n",
    "    correct_num = np.sum( predictions == labels )\n",
    "    return data_num, correct_num\n",
    "\n",
    "def cross_validate(n_folds, feature_vectors, labels, shuffle_order, method='SVM', parameters=None):\n",
    "    result_test_num = []\n",
    "    result_correct_num = []\n",
    "    \n",
    "    n_splits = N_splitter( range(2*DATA_NUM), n_folds )\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        print( \"Executing {0}th set...\".format(i+1) )\n",
    "        \n",
    "        test_elems = shuffle_order[ n_splits[i] ]\n",
    "        train_elems = np.array([])\n",
    "        train_set = n_splits[ np.arange(n_folds) !=i ]\n",
    "        for j in train_set:\n",
    "            train_elems = np.r_[ train_elems, shuffle_order[j] ]\n",
    "        train_elems = train_elems.astype(np.integer)\n",
    "\n",
    "        # train\n",
    "        model = train_model( feature_vectors[train_elems], labels[train_elems], method, parameters )\n",
    "        # predict\n",
    "        predictions = predict( model, feature_vectors[test_elems] )\n",
    "        # evaluate\n",
    "        test_num, correct_num = evaluate_model( predictions, labels[test_elems] )\n",
    "        result_test_num.append( test_num )\n",
    "        result_correct_num.append( correct_num )\n",
    "    \n",
    "    return result_test_num, result_correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_FOLDS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 1th set...\n",
      "Executing 2th set...\n",
      "Executing 3th set...\n",
      "CPU times: user 10.4 s, sys: 42 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans,corr = cross_validate(N_FOLDS, feature_vectors_csr, labels, shuffle_order, method='SVM', parameters=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision :  63.2 %\n"
     ]
    }
   ],
   "source": [
    "print( \"average precision : \", np.around( 100.*sum(corr)/sum(ans), decimals=1 ), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 6.53 ms, total: 2.35 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svm_model = train_model(\n",
    "    features=feature_vectors_csr[shuffle_order[0:950],:]\n",
    "    , labels=labels[shuffle_order[0:950]]\n",
    "    , method='SVM'\n",
    "    , parameters=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data :  [ 490 1276  794  892  504  463   48  289 1218 1137] correct label :  [0 1 1 1 0 0 0 0 1 1]\n",
      "predict label :  [1 1 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"data : \" ,shuffle_order[970:980], \"correct label : \", labels[shuffle_order[970:980]])\n",
    "print( \"predict label : \", predict(svm_model, feature_vectors_csr[shuffle_order[970:980], :]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* directed and co-produced by jodie foster . written by w . d . richter . cast : holly hunter , robert downey , jr . , anne bancroft , dylan mcdermott , charles durning , geraldine chaplin , steve guttenberg , claire danes , cynthia stevenson . distributed by paramount and polygram . the title \" home for the holidays \" suggests either a feel-good story , a family drama or a comedy , but guesses can be wrong . there was a made-for-tv movie with that title in 1972 which turned out to be a christmastime thriller . now , the current film's distributors have announced it as a comedy , but this description will do only if you stretch it . claudia ( holly hunter ) just lost her job as an art restorer at a museum . ( you wait a long time to find out that the museum is in chicago . ) with some trepidation , claudia leaves behind her sixteen-year old daughter ( we later learn in passing that hunter is unmarried ) and flies to another state to spend thanksgiving with her parents . ( you wait a long time to find out that it is maryland . if your eyes are peeled , you might catch the sign \" maryland lottery . \" ) the opening sequence tries for screwball comedy style , but it is only slightly weird and far from hilarious . soon the film goes into fast decline , in a structure that is a succession of sections , each with its title . \" flying \" is followed by \" mom and dad . \" mom is anne bancroft , nee anna maria luisa italiano , one of the very few catholics who can do a jewish mother turn , which she sort of does here . perhaps husband mel brooks is of help . dad ( charles durning ) is a retired something or other employee of an airline or of the baltimore airport . ( this is made clear only at the end . ) he is a kind of putterer now . pa and ma are eccentrics , sort of , but uninteresting as individuals and as a couple . if you remember bancroft as the famously seductive mrs . robinson in 1967 the graduate , you can now see her in bra and slip . she may be showing us how well kept she is at 64 , but her talent does not show in home for the holidays . the next chapter , \" company , \" centers mostly around claudia's brother tommy ( robert downey , jr . ) . tommy is gay , but you can't tell . you learn it only when you hear that \" he has broken with jack . \" on the other hand , tommy is relentlessly gay in the old sense , ebullient , bouncy and far , far too cute . you feel right away that downey is uncomfortable in , and unconvinced by his role . he arrives from boston with leo fish ( dylan mcdermott ) whom everybody takes for a new lover . each section has claudia in it but is normally focused on one or two additional characters . in \" relatives \" we meet mom's unmarried sister , retired schoolteacher geraldine chaplin . she too is an eccentric , unconvincing and unconvinced . her closeups are cruel . someone flatulates . there's an in-joke : a furnace repairman works for \" the big heat \" company , a reference to a classic film noir . in \" more relatives , \" we meet claudia's younger sister joanna , her sententious husband walter ( steve guttenberg ) and their two kids . the house becomes a zoo of agitation and hyperactivity , forced and seldom funny . only the cat is normal . next , \" the dinner \" reveals that tommy had married jack some time ago . joanna calls tommy a freak . he keeps his good mood but overacts again . by accident , joanna gets a plateful spilled on her dress . it turns out that leo fish is heterosexual . geraldine chaplin passionately kisses dad--on the mouth . watching the slicing of the turkey , it dawned on me that this film was trying to be a slice of life . but it is also a turkey that jodie foster directed--her second effort , after little man tate . just as responsible is the uneven writer w . d . richter , whose biggest hit was the dubious buckaroo banzai . his best works were slither , nickelodeon , and the excellent remake of invasion of the body snatchers . the stephen king story he scripted before home for the holidays was the disastrous needful things . in \" cleanup \" claudia's daughter calls , tells mom that she is disgusted with her boyfriend and is still a virgin . tommy and walter have a fight . jack telephones tommy . tommy is happy . the marriage is on again . the movie turns \" sensitive . \" \" now what ? \" follows . here , this mish-mashy , misguided , mis-written film predictably brings together leo fish and claudia . earlier , leo was passable as a quiet observer . now that he emotes , he is artificial . the couple have a too-cute impromptu date and kiss . taking leftovers to joanna's house , the sisters have a heart-to-heart talk . says claudia : \" we don't have to like each other . we're a family . \" this , i guess , is the moral of the story . viewer liberation comes with \" the point . \" claudia and leo , by mutual consent , will not have sex as they are going in different geographic ( and other ) directions . dad watches home movies . more sentiment . the real point is that this movie is pointless . that not a single performer is explored , seems to believe in his part , plays well , is involving , that no one uses more than two basic expressions . claudia takes the return plane . who comes in but leo , with a ridiculous lamp ( don't ask ) ? he proposes that they spend the two-hour flight sitting together . perhaps they'll go to sleep . that's what the film's audience ought to do too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_reader(neg_files[490-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメタチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 639 ms, total: 3min 35s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search_parameters = [\n",
    "    {'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4], 'C': [0.1, 1, 10, 100, 1000]},\n",
    "    {'kernel': ['linear'], 'C': [0.1, 1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "model = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(model, search_parameters)\n",
    "clf.fit( feature_vectors_csr, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paremters :  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "best scores :  0.7978571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"best paremters : \", clf.best_params_)\n",
    "print(\"best scores : \", clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 1th set...\n",
      "Executing 2th set...\n",
      "Executing 3th set...\n",
      "CPU times: user 10.3 s, sys: 46.9 ms, total: 10.3 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans,corr = cross_validate(N_FOLDS, feature_vectors_csr, labels, shuffle_order, method='SVM', parameters=clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision :  79.5 %\n"
     ]
    }
   ],
   "source": [
    "print( \"average precision : \", np.around( 100.*sum(corr)/sum(ans), decimals=1 ), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
